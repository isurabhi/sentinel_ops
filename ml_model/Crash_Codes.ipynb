{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"sentinel_ops_db\"]\n",
    "#collection = db[\"ms_teams_freezes\"]\n",
    "collection = db[\"device_crashes\"]\n",
    "# Define the query to filter the documents\n",
    "\n",
    "filtered_documents = collection.find()\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(list(filtered_documents))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set the 'timestamp' column as the index of the DataFrame\n",
    "data.set_index('time_stamp', inplace=True)\n",
    "# Sort the DataFrame by the index (timestamp) if needed\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "# Group by the date part alone and count the number of crashes per day\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['date'] = data['date'].dt.normalize()\n",
    "daily_crashes = data.groupby('date').size().reset_index(name='total_crash')\n",
    "#daily_crashes['date'] = pd.to_datetime(daily_crashes['date'], errors='coerce')\n",
    "#daily_crashes['total_crash'] = np.asarray(daily_crashes['total_crash'], dtype=np.float64)#pd.to_numeric(daily_crashes['total_crash'], errors='coerce')\n",
    "daily_crashes.set_index('date', inplace=True)\n",
    "\n",
    "daily_crashes = daily_crashes.asfreq('D')\n",
    "\n",
    "# Drop rows with NaN in the specific column\n",
    "# daily_crashes.dropna(subset=['total_crash'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train data 96\n",
      "Post len of train data96\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#print(forecast_df.columns)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m         \n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#Plot graph of training set, Test set and Algorithm prediction on Test set\u001b[39;00m\n\u001b[0;32m     36\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 37\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_crash\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum(), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_crash\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum(), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(forecast_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_mean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum(), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForecasted Data\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data, test_data = train_test_split(daily_crashes, test_size=0.2, shuffle=False)\n",
    "\n",
    "#train_size = int(len(daily_crashes) * 0.8)\n",
    "#train_data, test_data = daily_crashes[:train_size], daily_crashes[train_size:]\n",
    "\n",
    "#time_series = train_data.iloc[:, :]\n",
    "order=(7, 1, 1)\n",
    "\n",
    "# np_array = np.asarray(train_data['total_crash'], dtype=np.float64)\n",
    "\n",
    "model = ARIMA(train_data, order=order)\n",
    "model_fit = model.fit()\n",
    "\n",
    "print(f'len of train data {len(train_data)}')\n",
    "f_row = test_data.iloc[0:1]\n",
    "#train_data_df = pd.concat([train_data, f_row ], ignore_index=True)\n",
    "\n",
    "print(f'Post len of train data{len(train_data)}')\n",
    "\n",
    "#model = ARIMA(daily_crashes, order=order)\n",
    "#model_fit = model.fit()\n",
    "\n",
    "forecast = model_fit.forecast(steps=60)\n",
    "#forecast = pd.Series(forecast, index=test_data.index)\n",
    "\n",
    "#predictions_list = forecast.to_json(orient='records', date_format='iso') # predictions.iloc[0:steps]#.tolist()\n",
    "#train_data_list = train_data.to_json(orient='records', date_format='iso') # test_data.iloc[0:steps]#.tolist()\n",
    "forecast_df = forecast.to_frame()\n",
    "#print(forecast_df.columns)\n",
    "        \n",
    "#Plot graph of training set, Test set and Algorithm prediction on Test set\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_data['total_crash'].resample('D').sum(), label='Training Data')\n",
    "plt.plot(test_data['total_crash'].resample('D').sum(), label='Test Data')\n",
    "plt.plot(forecast_df['predicted_mean'].resample('D').sum(), label='Forecasted Data', color='green')\n",
    "#plt.plot(forecast[:1], label='Forecasted Data', color='green')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Crashes')\n",
    "plt.title('ARIMA Model - Total Crashes Forecast')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
